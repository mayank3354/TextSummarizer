{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MLOPS\\\\TextSummarizer\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\MLOPS\\\\TextSummarizer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    tokenizer_name: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.textSummarizer.constants import *\n",
    "from src.textSummarizer.utils.common import read_yaml,create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path=CONFIG_FILE_PATH,params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self ) -> DataTransformationConfig:\n",
    "        config=self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path,\n",
    "            tokenizer_name=config.tokenizer_name\n",
    "        )\n",
    "        return data_transformation_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\asyncio\\base_events.py\", line 595, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\asyncio\\base_events.py\", line 1881, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_12220\\2813221229.py\", line 3, in <module>\n",
      "    from transformers import AutoTokenizer\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1782, in __getattr__\n",
      "    value = getattr(module, name)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py\", line 38, in <module>\n",
      "    from .auto_factory import _LazyAutoMapping\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 40, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1781, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1793, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\generation\\utils.py\", line 29, in <module>\n",
      "    from ..cache_utils import (\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\cache_utils.py\", line 1872, in <module>\n",
      "    class OffloadedStaticCache(StaticCache):\n",
      "  File \"d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\cache_utils.py\", line 1940, in OffloadedStaticCache\n",
      "    offload_device: Union[str, torch.device] = torch.device(\"cpu\"),\n",
      "d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\cache_utils.py:1940: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  offload_device: Union[str, torch.device] = torch.device(\"cpu\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-02 13:05:54,039] INFO: config: PyTorch version 2.0.1 available.]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.textSummarizer.logging import logger\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_from_disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)\n",
    "\n",
    "    def convert_examples_to_features(self,example_batch):\n",
    "        input_encodings = self.tokenizer(example_batch['dialogue'], max_length = 1024, truncation = True)\n",
    "\n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            target_encodings = self.tokenizer(example_batch['summary'], max_length = 128 , truncation = True)\n",
    "\n",
    "        return {\n",
    "            'input_ids' : input_encodings['input_ids'],\n",
    "            'attention_mask': input_encodings['attention_mask'],\n",
    "            'labels': target_encodings['input_ids']\n",
    "        }\n",
    "    \n",
    "    def convert(self):\n",
    "        dataset_samsum = load_from_disk(self.config.data_path)\n",
    "        dataset_samsum_pt = dataset_samsum.map(self.convert_examples_to_features, batched=True)\n",
    "        dataset_samsum_pt.save_to_disk(os.path.join(self.config.root_dir, \"samsum_dataset\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-02 13:18:54,463] INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-02 13:18:54,475] INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-02 13:18:54,477] INFO: common: creating directory at: artifacts]\n",
      "[2025-01-02 13:18:54,501] INFO: common: creating directory at: artifacts/data_transformation]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dell\\.cache\\huggingface\\hub\\models--google--pegasus-cnn_dailymail. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]d:\\MLOPS\\TextSummarizer\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 14732/14732 [00:07<00:00, 2057.78 examples/s]\n",
      "Map: 100%|██████████| 819/819 [00:00<00:00, 2153.43 examples/s]\n",
      "Map: 100%|██████████| 818/818 [00:00<00:00, 2629.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 14732/14732 [00:00<00:00, 48376.20 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 819/819 [00:00<00:00, 80940.97 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 818/818 [00:00<00:00, 51939.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "config=ConfigurationManager()\n",
    "data_transformation_config=config.get_data_transformation_config()\n",
    "data_transformation = DataTransformation(config=data_transformation_config)\n",
    "data_transformation.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
